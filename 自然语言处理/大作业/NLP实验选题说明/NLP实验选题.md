# 题目概况

| 序号 |        题目        |     类型     | 语言 | 数据集（Train / Val / Test） |   指标   |
| :--: | :----------------: | :----------: | :--: | :--------------------------: | :------: |
|  1   |  中文语义病句识别  |    二分类    | 中文 |      7000 / 2000 / 1000      |    F1    |
|  2   |  中国古典诗歌配对  |    四选一    | 中文 |      7000 / 2000 / 1000      | Accuracy |
|  3   |     多语种识别     |    多分类    | 10种 |      7000 / 2000 / 1000      | Micro-F1 |
|  4   | 中医药命名实体识别 | 命名实体识别 | 中文 |       5258 / 656 / 657       | Macro-F1 |
|  5   |  中文医疗关系分类  |   关系分类   | 中文 |      7000 / 2000 / 1000      | Micro-F1 |
|  6   |    中文新闻摘要    |  生成式摘要  | 中文 |     10000 / 2000 / 1000      | Rouge-2  |
|  7   |    中文阅读理解    |  抽取式问答  | 中文 |     10625 / 2202 / 1129      |    EM    |
|  8   |    评价对象提取     |   对象抽取    | 中文 |     5973 / 1706 / 854        |   F1    |
|  9   |  评价对象级情感分类  |   情感分类    | 中文 |     936 / 268 / 135         | Accuracy |
|  10  |    问句相似度       |    相似度    | 中文 |      6553 / 1873 / 938       | Accuracy |
|  11  |   新闻文本分类     |    八分类    | 中文 |        3600 / 900 / 900         | Micro-F1 |
|  12  |   灾难推文识别      |   二分类    | 英文 |      5330 / 1523 / 763       | Accuracy |
|  13  |  中文短讯情感分析  |   情感分类   | 中文 |      8615 / 2462 / 1232      | Accuracy |
|  14  |    中文分词   |     分词     | 中文 | 1822596（字数）  / \ / 169247（字数） | F1  & OOV Rate |



# 题目一：中文语义病句识别

## 一、任务介绍

中文语义病句识别任务，旨在判断句子中是否含有不符合语义逻辑的错误，是一个二分类的问题。尽管句子结构符合语法规则，语义病句可能由于词语搭配不当、逻辑矛盾或用词错误等原因而导致句意不通畅。过往的文本错误主要针对拼写错误和语法错误，这些错误对于人类来说相对简单，往往是由外国语言学习者和中文母语写作者的疏忽而产生的。对于出版、教育等一些对深层次的中文语义错误识别有需求的行业，中文语义病句的识别将会有更大的帮助。语义病句经常出现在初高中的语文考试题目中，用来衡量学生对语文知识的掌握程度，这类语义病句对于学生来说是比较困难的，对于研究也有重大意义。

相比于拼写错误、语法错误不同，语义错误更加关注句子语义层面的合法性。数据例子如下所示：

|   类别   |                  原始句子                  |                  正确句子                  |
| :------: | :----------------------------------------: | :----------------------------------------: |
|   病句   |   英法联军 **烧毁并洗劫** 了北京圆明园。   |   英法联军 **洗劫并烧毁** 了北京圆明园。   |
|   病句   | 山上的水宝贵，把它留给 **晚上来** 的人喝。 | 山上的水宝贵，把它留给 **上来晚** 的人喝。 |
| 正确句子 |             国内彩电严重滞销。             |             国内彩电严重滞销。             |

## 二、数据集介绍

本数据集分为训练集、测试集和测试集三个 jsonl 文件，分别包含 7000、2000、1000 条数据，其中正确句子与病句比例为 1:1。每条数据包括：句子id、句子标签（0 为正确句子 / 1 为病句）、原始句子及其对应的正确句子。数据格式示例如下所示：

```python
{
  	"id": 3501, 
  	"label": 1, 
  	"sentence_pair": {
      	"source": "校运会上，李杰用相机把参赛同学拼搏的身影和助威鼓励的话语一一摄入镜头。", 
      	"target": "校运会上，李杰用相机把参赛同学拼搏的身影一一摄入镜头。"
    }
}
```

## 三、评价指标

本数据集评价指标采用二分类任务指标 **F1 值**：F1 值为准确率（Precision）和召回率（Recall）的调和平均数，取值范围在 0 到 1 之间，值越大表示模型性能越好。
$$
F1 = 2 \times \frac{P \times R}{P + R}
$$

- **准确率（P）**：正确预测为正类的样本数占所有预测为正类样本数的比例。其中，TP 为真正例（True Positives），FP 为假正例（False Positives）。

$$
P = \frac{TP}{TP + FP}
$$

- **召回率（Recall）**：正确预测为正类的样本数占所有实际为正类样本数的比例。其中，FN 为假负例（False Negatives）。

$$
R = \frac{TP}{TP + FN}
$$

> 注：可挑战中文语义病句纠正任务，针对病句生成正确句子，评价指标为 ChERRANT。





# 题目二：中国古典诗歌配对

## 一、任务介绍

中国古典诗歌匹配任务，旨在给定中国古典诗歌的现代描述，要求从候选的四句诗中选出与现代文描述语义匹配的那一句。这项任务需要对古典诗句的意境、情感和表达方式有深刻理解，并能够准确地将这些特征与现代语言中的描述对接。这不仅考验系统对古汉语和现代汉语的双重理解，还涉及到诗句的语义分析和精确匹配。

数据集利用古典诗歌和现代文翻译的平行语料构建正确选项，并利用正确选项从古代诗歌语料库中利用相似检索构造出错误候选。数据例子如下所示：

|      诗歌描述      | 一生当中疾病缠身今日独上高台。 |
| :----------------: | :----------------------------: |
|     候选诗句 0     |         一春多病几登台         |
|     候选诗句 1     |       **百年多病独登台**       |
|     候选诗句 2     |         百年多病负登临         |
|     候选诗句 3     |         况多愁病独登台         |
| 正确诗句的答案编号 |               1                |

## 二、数据集介绍

本数据集分为训练集、测试集和测试集三个 jsonl 文件，分别包含 7000、2000、1000 条数据。

- 每条数据包括：句子id、诗歌描述、候选诗句（4 个）、正确诗句的答案编号。

数据格式示例如下所示：

```python
{
  	"id": 5253, 
  	"translation": "自说是新近里立功封官。", 
  	"choices": ["新封万户侯", "中道敕封侯", "新封千户侯", "自道新封侯"], 
  	"answer": 3
}
```

## 三、评价指标

本数据集评价指标采用 **准确率**（Accuracy）：模型正确预测的样本数量占总样本数量的比例。
$$
Acc = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(x_i = y_i)
$$
其中，N 为总样本数量，x 为预测编号，y 为答案编号，$\mathbb{I}(x_i = y_i)$ 为指示函数，若预测编号和答案编号相同取值为 1，反之取值为 0。





# 题目三：多语种识别

## 一、任务介绍

多语种识别任务，旨在自动检测并识别文本数据中使用的语言种类。该任务涉及对多种语言的文本输入进行分类，判断其所属语言，例如是否为英文、中文、法文等。这项任务在多语种用户界面、跨语言信息检索、内容管理和机器翻译等领域具有广泛应用，有助于实现多语言环境中的无缝交流和信息处理。

## 二、数据集介绍

本数据集来自维基百科，分为训练集、测试集和测试集三个 csv 文件，分别包含 7000、2000、1000 条数据。

- 每条数据包括：文本和语言类别。
- 语言类别有 10 类，每个类别包含 1000 条数据，其中语言类别分别为：英语、中文、日语、韩语、泰语、拉丁语、法语、西班牙语、俄语、阿拉伯语。

数据格式示例如下所示：

|                             Text                             | language |
| :----------------------------------------------------------: | :------: |
| the glycerol--phosphate shuttle is a mechanism that regenerates nad from nadh a by-product of glycolysis its importance in transporting reducing equivalents is secondary to the malate-aspartate shuttle | English  |
| 在孟山都法商业生产之前，大部分的乙酸是由乙醛氧化制得。尽管不能与甲基羰基化相比，此法仍然是第二种工业制乙酸的方法。乙醛可以通过氧化丁烷或轻石脑油制得，也可以通过乙炔水合后生成。当丁烷或轻石脑油在空气中加热，并有多种金属离子包括镁，钴，铬以及过氧根离子催化，会分解出乙酸。化学方程式如下： | Chinese  |
| マキが恋愛の練習用に理想の男子像を描いた自作抱き枕で、カバーに学生服姿の少年を描いているが、その顔は「もじゃもじゃ頭・どんぐりマナコにたらこ唇」と下手。サヨにその存在を知られた際に、スズが「ダッバーン・ダバダバ男爵」と命名したのをきっかけに、リコは「伯爵」、マキは「侯爵」、サヨは「公爵」と呼ぶがこれらの名称はほとんど定着しなかった。「ダバダバ」はスズが食事中にソースをかけすぎた際に家族が、『pm』のテーマを口ずさみ、それが頭の中から離れなくなってしまったため。マキが生徒会費からこっそり着服・横領して購入した学生服（後に南中指定のものと判明）を着させたりもしている。 | Japanese |

## 三、评价指标

本数据集评价指标采用 **Micro-F1 值**：相比于传统 F1 值（见题目一），Micro-F1 值在计算时考虑所有类别的真正例、假正例和假负例的总和，从而给出一个全局的评估。
$$
F1 = 2 \times \frac{Micro-P \times Micro-R}{Micro-P + Micro-R} \\
Micro-P = \frac{Micro-TP}{Micro-TP + Micro-FP} \\
Micro-R = \frac{Micro-TP}{Micro-TP + Micro-FN}
$$
其中：Micro-TP、Micro-FP 和 Micro-FN 为所有类别的 TP、FP 和 FN 相加。





# 题目四：中医药命名实体识别

## 一、任务介绍

中医药命名实体识别任务，旨在从中医药相关文本中自动识别并提取出具有特定意义的实体，例如中药名称、疾病名称、症状、方剂、功效等。这一任务涉及对中医药领域的专有词汇进行分类和标注，以便构建结构化的知识库，支持进一步的分析和应用。中医药命名实体识别任务在中医药文献分析、知识图谱构建、智能问答系统及临床决策支持等方面有广泛应用。它有助于系统化地整理中医药知识，促进信息检索和数据挖掘，进而推动中医药数字化和智能化的发展。数据例子如下所示：

|     句子      | 结论：二参三草汤治疗慢性萎缩性胃炎脾虚湿热证有效 |
| :-----------: | :----------------------------------------------: |
| 实体 - 类别 1 |                二参三草汤 - 方剂                 |
| 实体 - 类别 2 |            慢性萎缩性胃炎 - 西医诊断             |
| 实体 - 类别 3 |               脾虚湿热 - 中医证候                |

## 二、数据集介绍

本数据集分为训练集、测试集和测试集三个 txt 文件，分别包含 5258、656、657 条数据，每条数据可能包含多个实体。

- 数据使用 “OBI-实体类别” 方式进行标注（B 表示实体的开始 / I 表示实体的中间部分 / O 表示非实体部分）；
- 实体分为 10 类，分别为：临床表现、中药、西医诊断、中医证候、中医治疗、方剂、西医治疗、中医治则、中医诊断、其他治疗。
- 数据集将每个字存储为一行，不同数据间使用 “空行” 间隔。

数据格式示例如下所示：

```python
结 O
论 O
： O
二 B-方剂
参 I-方剂
三 I-方剂
草 I-方剂
汤 I-方剂
治 O
疗 O
慢 B-西医诊断
性 I-西医诊断
萎 I-西医诊断
缩 I-西医诊断
性 I-西医诊断
胃 I-西医诊断
炎 I-西医诊断
脾 B-中医证候
虚 I-中医证候
湿 I-中医证候
热 I-中医证候
证 O
有 O
效 O
```

## 三、评价指标

本数据集评价指标采用 **Macro-F1 值**：Macro-F1 值首先计算每个类别的 F1 值（见题目一），然后取这些 F1 值的平均。这个方法能够更好地反映模型在各个类别上的表现，尤其是在类别分布不均衡的情况下。
$$
Macro-F1 = \frac{1}{N} \sum_{i = 1}^N F1_i \\
F1_i = 2 \times \frac{P_i \times R_i}{P_i + R_i}
$$
其中：N 为类别数量，$F1_i$ 为第 i 个类别的 F1 值。

> 注：需要实体边界和类别完全正确才算识别正确。





# 题目五：中文医疗关系分类

## 一、任务介绍

中文医疗关系分类任务，旨在从中文医疗文本中识别并分类不同类型的医疗关系，这些关系通常涉及药物、症状、疾病、治疗方法等实体之间的联系。例如，该任务可能需要识别并分类“药物-治疗疾病”、“症状-诊断疾病”或“疾病-引发并发症”等关系类型，是个多分类问题。通过训练模型识别并分类这些关系，可以帮助构建医疗知识图谱，支持智能诊断、医学研究和健康信息管理等应用，有助于提升医疗数据的利用效率和准确性。数据例子如下所示：

|                             句子                             |    头实体    |   尾实体   | 关系 |
| :----------------------------------------------------------: | :----------: | :--------: | :--: |
| （二）婴儿**上消化道出血**常见原因：吞入母血、反流性食管炎、**应激性溃疡**、胃炎、出血性疾病以及Mallory-Weiss综合征。 | 上消化道出血 | 应激性溃疡 | 病因 |

## 二、数据集介绍

本数据集分为训练集、测试集和测试集三个 jsonl 文件，分别包含 7000、2000、1000 条数据。

- 每条数据包括：句子id、头实体、尾实体、关系、句子。
- 关系类别有 10 类，每个类别包含 1000 条数据，其中关系类别分别为：临床表现、药物治疗、同义词、病因、并发症、病理分型、实验室检查、辅助治疗、相关（导致）、影像学检查。

数据格式示例如下所示：

```python
{
  	"id": 0, 
  	"sentence": "早期先天性梅毒多见于早产儿、低出生体重儿或小于胎龄儿;生后的发育、营养状况落后于同胎龄儿。⑥中枢神经系统症状:在新生儿期罕见，多在生后3~6个月时出现脑膜炎症状,脑脊液中淋巴细胞数增高，蛋白呈中度增高，糖正常。", 
  	"h": "先天性梅毒", 
  	"t": "脑膜炎症状", 
  	"r": "临床表现"
}
```

## 三、评价指标

本数据集评价指标采用 **Micro-F1 值**：相比于传统 F1 值（见题目一），Micro-F1 值在计算时考虑所有类别的真正例、假正例和假负例的总和，从而给出一个全局的评估。
$$
F1 = 2 \times \frac{Micro-P \times Micro-R}{Micro-P + Micro-R} \\
Micro-P = \frac{Micro-TP}{Micro-TP + Micro-FP} \\
Micro-R = \frac{Micro-TP}{Micro-TP + Micro-FN}
$$
其中：Micro-TP、Micro-FP 和 Micro-FN 为所有类别的 TP、FP 和 FN 相加。





# 题目六：中文新闻摘要

## 一、任务介绍

中文新闻摘要任务，旨在从长篇新闻文本中提取出核心信息，并生成简短、准确的摘要。这一任务可以通过抽取式或生成式的方法实现：抽取式方法从原文中挑选出最重要的句子进行组合，而生成式方法则通过理解新闻内容，用自然语言生成新的摘要。中文新闻摘要任务需要准确捕捉新闻中的关键信息和主题，确保摘要简洁且涵盖主要内容。该任务在新闻聚合、信息检索和新闻推荐系统中有广泛应用，能够帮助用户快速获取新闻要点，提升信息获取效率。数据格式示例如下表所示：

|                           新闻文章                           |                新闻摘要                 |
| :----------------------------------------------------------: | :-------------------------------------: |
| 一辆小轿车，一名女司机，竟造成9死24伤。日前，深圳市交警局对事故进行通报：从目前证据看，事故系司机超速行驶且操作不当导致。目前24名伤员已有6名治愈出院，其余正接受治疗，预计事故赔偿费或超一千万元。 | 深圳机场9死24伤续：司机全责赔偿或超千万 |

## 二、数据集介绍

本数据集分为训练集、测试集和测试集三个 jsonl 文件，分别包含 10000、2000、1000 条数据。

- 每条数据包括：句子id、新闻文章和新闻摘要，其中正文平均字数 104，摘要平均字数 18。

数据格式示例如下所示：

```python
{
  	"id": 1, 
  	"title": "深圳机场9死24伤续：司机全责赔偿或超千万", 
  	"content": "一辆小轿车，一名女司机，竟造成9死24伤。日前，深圳市交警局对事故进行通报：从目前证据看，事故系司机超速行驶且操作不当导致。目前24名伤员已有6名治愈出院，其余正接受治疗，预计事故赔偿费或超一千万元。"
}
```

## 三、评价指标

本数据集评价指标采用 **ROUGE-2**：ROUGE-2 计算生成文本与参考文本的 2-gram （两个连续的单词组成的词组）的召回率，能够捕捉到词的重要性。
$$
ROUGE-2 = \frac{\sum_{gram_2 \in title} Count_{match}(gram_2)}{\sum_{gram_2 \in title} Count(gram_2)}
$$
其中，title 为参考摘要，$\sum_{gram_2 \in title} Count(gram_2)$ 为参考摘要的 2-gram 总数，$\sum_{gram_2 \in title} Count_{match}(gram_2)$ 为生成文本与参考文本的 2-gram 匹配数。

> 注：可增加评价指标  **ROUGE-1**、 **ROUGE-l** 等。





# 题目七：中文阅读理解

## 一、任务介绍

中文阅读理解任务，旨在让计算机理解并回答与中文文本相关的问题。该任务通常包括输入一段中文文本，以及基于该文本提出的一个或多个问题，模型需从文本中提取或生成相应的答案。中文阅读理解任务可以涉及多种问题类型，如事实型问题、推理型问题、摘要型问题等，要求系统能够准确理解文本的内容、结构和隐含意义。中文阅读理解在智能问答系统、教育辅导、知识图谱构建等领域有广泛应用，有助于实现信息的自动获取和用户辅助决策，提高信息处理的效率和准确性。数据格式示例如下表所示：

|                             文本                             |            问题             |  答案  |
| :----------------------------------------------------------: | :-------------------------: | :----: |
| 主教制源自 **天主教** 的主教制度，几乎和天主教的主教制度一模一样，唯一不同的是主教亦可以结婚。天主教的主教制是在使徒们去世后于第二、三世纪兴起的主教制度，所以可以说主教制是整个基督宗教中历史最悠久的神职人员制度。现在行主教制的新教教会已经很少，圣公会就是沿用主教制，从教会制度和礼仪上看来，圣公会基本上属大公教会传统。路德宗和卫理公会则由各区会自行选择使用主教制还是长老制；在香港和澳门，路德会和卫理公会就选用了长老制...... | 新教的主教制度源自于哪一教? | 天主教 |

## 二、数据集介绍

本数据集为开放域的繁体中文机器阅读理解数据集，分为训练集、测试集和测试集三个 jsonl 文件。

- 每条数据为一篇文章，以字典格式存储，包括：文章标题、文章id、段落，一篇文章可能包含多个段落；
- 段落以字典格式存储，包括：段落内容、段落编号、问题，一篇文章可能包含多个问题；
- 问题以字典格式存储，包括：问题内容、问题编号、答案（答案文本和答案起始位置）。

数据集统计信息如下：

| 数据集 | 文章数 | 段落数 | 问题数 |
| :----: | :----: | :----: | :----: |
| train  |  750   |  3150  | 10625  |
|  val   |  250   |  621   |  2202  |
|  test  |  125   |  326   |  1129  |

数据格式示例如下所示：

```python
{
  	"title": "北齐", 
  	"id": "1315", 
  	"paragraphs": [
      	{
          	"context": "北齊是中國北朝時的鮮卑王朝之一。550年6月9日，由文宣帝高洋取代東魏建立，建國號齊，建元天保，遷都鄴城，以晉陽為別都。史稱北齊或後齊，以別於南齊。以皇室姓高，又稱高齊。北齊歷經文宣帝高洋、廢帝高殷、孝昭帝高演、武成帝高湛、後主高緯、幼主高恆六帝，577年被北周消滅，共享國二十八年。幼主高恆時期，北周在北周武帝的統治下日漸興盛，而北齊則衰落。577年北周統一北方，北齊滅亡。北齊滅亡後，境內的士族大多遷到關中，成為北周臣民。三年後北周外戚楊堅篡位，建國號隋並南下滅陳結束中原自魏晉南北朝長達四百年的分裂局面。", 
          	"id": "1315-1", 
          	"qas": [
              	{"id": "1315-1-1", "question": "中國歷史上哪一個朝代將東魏取代？", "answers": {"text": "北齊", "answer_start": 0}}, 
              	{"id": "1315-1-2", "question": "北齊滅在哪一國家的手中？", "answers": {"text": "北周", "answer_start": 129}}, 
              	{"id": "1315-1-3", "question": "高恆在北齊滅亡後成為哪一國的國民？", "answers": {"text": "北周", "answer_start": 208}}
            ]
        }, 
      	{
          	"context": "北齊繼承了東魏所控制的地區，占有今黃河下游流域的河北、河南、山東、山西以及蘇北、皖北的廣闊地區。同時與其並存的王朝有西魏、北周、梁、陳等。北齊天保三年以後，北擊庫莫奚、東北逐契丹、西北破柔然，西平山胡，南取淮南，勢力一直延伸到長江邊，這時北齊的國力達到鼎盛。北齊的農業、鹽鐵業、瓷器製造業都相當發達，是同陳、北周鼎立的三個國家中最富庶的。北齊繼續推行均田制，大體上與北魏相同，但也略有變化。例如，北齊取消了受倍田的規定，不過一夫一婦的實際受田數仍相當於倍田，北魏對奴婢受田沒有限制。北齊則按官品限制在300人至600人之間。另外還規定了賦稅。此外，魏收於此時編寫了《魏書》。", 
          	"id": "1315-2", 
          	"qas": [
              	{"id": "1315-2-1", "question": "東魏在滅亡後由哪一國家繼承其所控制的地區？", "answers": {"text": "北齊", "answer_start": 0}}, 
              	{"id": "1315-2-2", "question": "北齊的國力在什麼時候達到鼎盛？", "answers": {"text": "北齊天保三年以後", "answer_start": 69}}, 
              	{"id": "1315-2-3", "question": "受倍田的規定在什麼朝代被取消？", "answers": {"text": "北齊", "answer_start": 198}}
            ]
        }
    ]
}
```

## 三、评价指标

本数据集评价指标采用 **EM 指标**（Exact Match）：EM 指标严格要求模型的预测结果与标准答案的文本 **完全匹配**。
$$
EM = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(x_i = y_i)
$$
其中，N 为总样本数量，x 为预测答案，y 为标准答案，$\mathbb{I}(x_i = y_i)$ 为指示函数，若预测答案和标准答案相同取值为 1，反之取值为 0。



# 题目八：评价对象抽取

## 一、任务介绍
评价对象抽取任务的主要目标是从文本中识别出特定的对象或实体，这些对象通常是文本中被描述、评论或评价的具体事物、概念或人物。该任务的核心在于能够从自然语言中提取出这些评价对象，使得后续的情感分析、内容总结等任务能够专注于这些关键信息上。因此，评价对象抽取对于提升信息处理效率、精准分析用户情感以及支持企业决策等方面都有着重要的价值。

## 二、数据集介绍
使用数据集为中国科学院的**COTE-BD**。数据集由若干样本组成，每条样本为 JSONL 格式，`s`字段为文本，`ot`字段为文本对应的评价对象。数据集结构如下：

- 文本 (s): 一个包含评价内容的文本段落。
- 评价对象 (ot): 系统需要从文本 s 中抽取的对象。

数据集示例如下：
```
{
	"s": "芝罘岛骑车去过几次，它挺壮观的，毕竟是我国典型的也是最大的陆连岛咯!我喜欢去那儿，反正全岛免费咯啊哈哈哈！风景的确不错而且海水也很干净，有些地方还是军事管理，禁地来着，但是我认识军官。", 
	"ot": "芝罘岛"
}
```

## 三、评价指标
为了评估抽取的性能，本实验可考虑以下指标：
 
1. **精确率（Precision）**：  
   $$
   \text{Precision} = \frac{TP}{TP + FP}
   $$

2. **召回率（Recall）**：  
   $$
   \text{Recall} = \frac{TP}{TP + FN}
   $$

3. **F1分数（F1 Score）**：
   $$
   F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
   $$

其中，TP 为模型正确提取的评价对象数量，FP 为模型错误提取的评价对象数量，FN 为模型未能提取的真实评价对象数量。


# 题目九：评价对象级情感分类

## 一、任务介绍
评价对象情感分类任务的目标是基于输入文本中的特定评价对象，自动识别出用户或作者对该对象所表达的情感类别。这一任务通常包括识别情感的正面、负面或中性等类别，甚至在某些应用中可能涉及更细致的情感类型划分。评价对象情感分类在情感分析领域中具有广泛的应用，尤其是在产品评论、用户反馈、社交媒体分析等场景中。因此，评价对象情感分类任务在多个领域具有重要的应用价值，为各类情感分析任务提供了更细致、更具针对性的情感识别能力，有助于全面、精准地捕捉用户对特定对象的情感态度。

## 二、数据集介绍
使用数据集为哈尔滨工业大学的**SE-ABSA16_PHNS**。数据集中的每个样本是一个三元组label，text_a和text_b，text_b为输入文本，text_a为评价对象，label是针对该评价对象的情感类别：

- 输入文本 (text_b): 包含用户评论或反馈的文本段落
- 评价对象 (text_a): 需要进行情感分类的具体对象
- 情感类别 (label): 指定对象的情感分类，包括“积极”（1）、“消极”（0）

数据集示例如下：
| label | text_a | text_b |
| :---: | :---: | :---: | 
| 1 | phone#operation_performance | 苹果iPhone5新机到手 对比4S使用感受... |
| 0 | software#operation_performance | 苹果iPhone5新机到手 对比4S使用感受... |

## 三、评价指标
本数据集评价指标采用 **准确率**（Accuracy）：模型正确预测的样本数量占总样本数量的比例。
$$
Acc = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(x_i = y_i)
$$
其中，N 为总样本数量，x 为预测编号，y 为答案编号，$\mathbb{I}(x_i = y_i)$ 为指示函数，若预测编号和答案编号相同取值为 1，反之取值为 0。


# 题目十：问句相似度

## 一、任务介绍
问句相似度分析任务旨在评估两个中文问句之间的语义相似度，其目标是判断两个问句是否表达了相似或相同的意图和信息。通过对问句的句法结构、用词选择、语义内容等方面的深入分析，可以确定问句之间的相似程度。两个问句在表述上可能存在明显差异，例如词汇选择或语序不同，但如果它们在语义上等价，则可以被视为相似的问句。反之，不相似的问句在意义上通常存在较大的差异，可能涉及不同的主题或表达完全不同的意图。因此，问句相似度分析对于优化各类自然语言处理任务、增强系统的智能性和响应能力具有重要作用。

## 二、数据集介绍
**LCQMC**是百度知道领域的中文问题匹配数据集，目的是为了解决在中文领域大规模问题匹配数据集的缺失。该数据集从百度知道不同领域的用户问题中抽取构建数据。本数据集包含多个问句对及其相似度标记。数据集的结构如下：

- 问句1: 第一个问句
- 问句2: 第二个问句
- 相似度: 标签，1表示相似，0表示不相似

数据集示例如下：
| 问句1 | 问句2 | 相似度 |
| :---: | :---: | :---: | 
| 喜欢打篮球的男生喜欢什么样的女生 | 爱打篮球的男生喜欢什么样的女生 | 1 |
| 求介绍有什么好玩的单机策略三国游戏？ | 好玩的策略型三国网页游戏，有人推荐吗？ | 0 |

## 三、评价指标
本数据集评价指标采用 **准确率**（Accuracy）：模型正确预测的样本数量占总样本数量的比例。
$$
Acc = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(x_i = y_i)
$$
其中，N 为总样本数量，x 为预测编号，y 为答案编号，$\mathbb{I}(x_i = y_i)$ 为指示函数，若预测编号和答案编号相同取值为 1，反之取值为 0。


# 题目十一：新闻文本分类

## 一、任务介绍
文本分类任务的核心目标是基于文本内容的特征，将其自动归入预定义的类别中。具体而言，对于新闻文本分类，通过分析新闻文本中的关键词、句式结构、语义模式及主题信息等多维度特征，能够将新闻归类到相应的类别中，例如体育、科技、娱乐、财经等。文本分类的过程通常涉及文本预处理、特征提取及分类模型的训练和预测。该任务在多个实际应用中具有重要意义，尤其是在新闻推荐系统中，可以根据用户兴趣推荐相关类别的新闻；在信息过滤场景中，通过分类过滤不相关的内容，有效提高用户体验和信息获取的精准性。此外，在舆情分析中，文本分类能够帮助识别各类新闻的类别分布，从而及时把握公众关注的热点和趋势。因此，文本分类任务在提升信息处理效率、优化内容分发及增强舆情监测能力等方面，具有广泛而重要的应用价值。

## 二、数据集介绍
数据集为搜狗新闻数据集，**搜狗分类新闻20061127**，包含train、val和test两个文件夹，三个文件夹下内容都如下展示：
├── Culture
│   ├── news1.txt
│   ├── news2.txt
│   └── ...
├── Sports
│   ├── news1.txt
│   ├── news2.txt
│   └── ...
├── Finance
│   └── ...
├── Education
│   └── ...
├── Health
│   └── ...
├── Military
│   └── ...
├── IT
│   └── ...
└── Travel
    └── ...

## 三、评价指标
本数据集评价指标采用 **Micro-F1 值**：相比于传统 F1 值，Micro-F1 值在计算时考虑所有类别的真正例、假正例和假负例的总和，从而给出一个全局的评估。
$$
F1 = 2 \times \frac{Micro-P \times Micro-R}{Micro-P + Micro-R} \\
Micro-P = \frac{Micro-TP}{Micro-TP + Micro-FP} \\
Micro-R = \frac{Micro-TP}{Micro-TP + Micro-FN}
$$
其中：Micro-TP、Micro-FP 和 Micro-FN 为所有类别的 TP、FP 和 FN 相加。


# 题目十二：灾难推文识别

## 一、任务介绍
智能手机如今无处不在，为人们提供了实时分享信息的便利，使得他们可以迅速发布他们所目击的突发事件或紧急情况。正因为这一点，越来越多的机构，尤其是救灾组织、政府部门和新闻机构，开始关注如何以程序化的方式来监控社交媒体平台，如Twitter，以期能够第一时间获取灾难信息、了解事件发展并作出快速反应。然而，个人在社交媒体上的话语是否真正指向一场灾难，往往并不显而易见。许多用户的发布内容可能带有个人情绪、调侃、夸张，甚至谣言，导致信息真伪难辨。以这个例子为例：
![alt text](tweet_screenshot.png)
作者明确使用了 “ABLAZE” 这个词，但其含义是隐喻性的。这对人类来说是一眼就能明白的，尤其是在视觉辅助下。但机器就不那么清楚了。

## 二、数据集介绍
数据集由 figure-eight 公司创建，是手动分类的推文的数据集，结构如下：
- **id** - 每条推文的唯一标识符
- **text** - 推文的文本
- **location** - 推文的发送位置（可能为空）
- **keyword** - 推文中的特定关键词（可能为空）
- **target** - 这表示一条推文是否是关于真正的灾难，`1`代表是，`0`代表不是

数据示例如下：
| id | text | location | keyword | target |
| :---: | :---: | :---: | :---: | :---: |
| 7148 | STERLING-SCOTT on the Red Carpet at a fundraiser for 'OSO Mudslide' https://t.co/mA4ra7AtqL http://t.co/cg579wlDnE | Malibu/SantaFe/Winning! | mudslide | 1 |
| 4876 | Whether you like it or not everything comes out of the dark be ready for that shit to explode ?? |  | explode | 0 |

## 三、评价指标
本数据集评价指标采用 **准确率**（Accuracy）：模型正确预测的样本数量占总样本数量的比例。
$$
Acc = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(x_i = y_i)
$$
其中，N 为总样本数量，x 为预测编号，y 为答案编号，$\mathbb{I}(x_i = y_i)$ 为指示函数，若预测编号和答案编号相同取值为 1，反之取值为 0。


# 题目十三：中文短讯情感分析

## 一、任务介绍
本实验任务是对中文短信内容进行情感分析，判定每条短信的情感是**积极（positive）**还是**消极（negative）**。具体来说，该任务通过分析短信文本中的语言模式、关键词、句式结构及情绪表达等特征，判断出发送者在文本中所传达的情感态度。

## 二、数据集介绍
数据集包含几千条中文短讯，每条短讯都有对应的情感标签。情感标签分为两类：
- **positive**：表示该短讯情感积极
- **negative**：表示该短讯情感消极

数据集结构如下：
- **text**：包含短讯内容
- **labels**：包含短讯对应的情感

## 三、评价指标
为了评估分类性能，本实验可考虑以下分类指标：
1. **准确率 (Accuracy)**：
   $$
   \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
   $$
- TP（True Positive）: 正确分类为Pos的样本数量（实际为Pos，预测为Pos）。
- TN（True Negative）: 正确分类为Neg的样本数量（实际为Neg，预测为Neg）。
- FP（False Positive）: 错误分类为Pos的样本数量（实际为Neg，预测为Pos）。
- FN（False Negative）: 错误分类为Neg的样本数量（实际为Pos，预测为Neg）。


# 题目十四：中文分词

## 一、任务介绍
中文分词是自然语言处理中的基础任务之一，由于汉字之间没有天然的空格分隔，分词是将连续的汉字序列切分为一个个有意义的词汇单元。分词不仅要求对汉字序列进行正确的切分，还需要考虑到不同词汇之间的关系、歧义以及多义词的问题。高质量的分词结果有助于提升后续自然语言处理任务的效果，如情感分析、机器翻译、信息检索等，因此中文分词是实现更高层次语言理解和分析的基础。

## 二、数据集介绍
**ICWB2**是一个中文分词标准数据集，专门用于评估中文分词系统的性能。这个数据集是由中国信息处理学会（SIGHAN）提供的，主要用于其举办的中文分词评测活动。ICWB2数据集包含多种类型的文本，帮助研究者评估不同方法在中文分词任务上的表现。数据集结构如下：
- **gold**:包含测试数据的标准分割以及训练数据单词列表
- **test**:包含未分段的测试数据
- **train**:包含分段训练数据
- **scripts**:包含评分脚本和简单分段器
- **doc**:包含数据使用说明

## 三、评价指标
1. **精确率（Precision）**：  
   $$
   \text{Precision} = \frac{TP}{TP + FP}
   $$

**召回率（Recall）**：  
   $$
   \text{Recall} = \frac{TP}{TP + FN}
   $$

**F1分数（F1 Score）**：
   $$
   F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
   $$
- TP（True Positive）: 正确分词的词数量。
- FP（False Positive）: 错误分词的词数量。
- FN（False Negative）: 漏分词的数量。

2. **OOV（Out-Of-Vocabulary）**
   $$
   \text{OOV Rate} = \frac{\text{OOV Words}}{\text{Total Words}} \times 100\%
   $$
- OOV Words: 在分词结果中未在词汇表中注册的词汇数量。
- Total Words: 分词结果中的总词汇数量。
