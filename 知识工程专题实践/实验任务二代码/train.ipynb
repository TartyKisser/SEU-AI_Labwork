{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T10:17:08.464699Z",
     "start_time": "2025-04-10T10:17:04.857876Z"
    }
   },
   "source": [
    "# coding=utf-8\n",
    "import torch\n",
    "from torch_geometric import transforms as T\n",
    "torch.manual_seed(3407)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:17:08.480206Z",
     "start_time": "2025-04-10T10:17:08.467204Z"
    }
   },
   "cell_type": "code",
   "source": "### Step 1 定义模型和图数据",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:17:36.761533Z",
     "start_time": "2025-04-10T10:17:08.481708Z"
    }
   },
   "source": [
    "from src.model import GCN, DeepGCN, GAT\n",
    "from src.tools import homo_data, split_homo_graph, Study, FocalLoss\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load and transform the data\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.ToDevice(device)])\n",
    "data, id_mapping = homo_data(\n",
    "    \"./data/\", transform=transform, fill_mode=\"stats\", return_id_mapping=True\n",
    ")\n",
    "\n",
    "# Create a split based on parcel IDs (for example, using first 70% parcels for training)\n",
    "# Assuming you want to split by some criterion, like parcel IDs\n",
    "# 在主程序文件中\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 假设你已经加载了data\n",
    "# data, id_mapping = homo_data(\"./data/\", return_id_mapping=True)\n",
    "\n",
    "# 获取节点数量和类别数量\n",
    "num_nodes = data.x.size(0)\n",
    "num_classes = len(torch.unique(data.parcel_types))\n",
    "\n",
    "# 创建分层采样的索引\n",
    "train_idx, val_idx, test_idx = [], [], []\n",
    "\n",
    "# 为每个类别进行分层采样以保持类别分布\n",
    "for c in range(num_classes):\n",
    "    # 获取该类别的所有节点索引\n",
    "    idx = torch.nonzero(data.parcel_types == c).squeeze().tolist()\n",
    "    # 确保idx是一个列表（处理只有一个样本的情况）\n",
    "    if not isinstance(idx, list):\n",
    "        idx = [idx]\n",
    "    \n",
    "    # 如果该类别没有样本，跳过\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    \n",
    "    # 打乱索引\n",
    "    perm = torch.randperm(len(idx))\n",
    "    idx = torch.tensor(idx)[perm]\n",
    "    \n",
    "    # 按照70%/15%/15%的比例划分（或者你想要的其他比例）\n",
    "    n_train = int(0.7 * len(idx))\n",
    "    n_val = int(0.15 * len(idx))\n",
    "    \n",
    "    train_idx.extend(idx[:n_train].tolist())\n",
    "    val_idx.extend(idx[n_train:n_train+n_val].tolist())\n",
    "    test_idx.extend(idx[n_train+n_val:].tolist())\n",
    "\n",
    "# 创建掩码\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "# 添加掩码到数据对象\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "# 然后使用Study类进行训练\n",
    "\n",
    "# 在训练前确保掩码和标签的形状匹配\n",
    "if hasattr(data, 'parcel_types') and hasattr(data, 'train_mask'):\n",
    "    if data.train_mask.size(0) != data.parcel_types.size(0):\n",
    "        print(f\"警告：掩码形状({data.train_mask.size(0)})与标签形状({data.parcel_types.size(0)})不匹配\")\n",
    "        # 裁剪掩码以匹配标签长度\n",
    "        data.train_mask = data.train_mask[:data.parcel_types.size(0)]\n",
    "        data.val_mask = data.val_mask[:data.parcel_types.size(0)]\n",
    "        data.test_mask = data.test_mask[:data.parcel_types.size(0)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Or use RandomLinkSplit for link prediction tasks\n",
    "# split = T.RandomLinkSplit(num_test=0.1, num_val=0.1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告：掩码形状(110836)与标签形状(110803)不匹配\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:17:36.823564Z",
     "start_time": "2025-04-10T10:17:36.763034Z"
    }
   },
   "source": [
    "# model = DeepGCN(data.num_features, 128, 64, 14).to(device)\n",
    "# 获取类别数量\n",
    "\n",
    "\n",
    "# 初始化模型\n",
    "model = GCN(\n",
    "    in_channels=data.num_features, \n",
    "    hidden_channels=128,\n",
    "    out_channels=64,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "study = Study(model, data)  # 不需要提供split参数\n",
    "# model = GAT(data.num_features, 128, 64, 5).to(device)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 训练"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:17:37.568721Z",
     "start_time": "2025-04-10T10:17:36.825072Z"
    }
   },
   "source": [
    "CKPT_DIR = f\"./ckpt/{model.name}/\"\n",
    "NUM_EPOCH = 100\n",
    "# 现在可以训练模型\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "study.train(NUM_EPOCH, optimizer, save_dir=CKPT_DIR)"
   ],
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [110803] at index 0 does not match the shape of the indexed tensor [110836, 33] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-4\u001B[39m)\n\u001B[0;32m      5\u001B[0m criterion \u001B[38;5;241m=\u001B[39m FocalLoss(alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2.0\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mNUM_EPOCH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCKPT_DIR\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\知识工程专题实践\\xuezhang\\xuezhang\\src\\tools\\trial.py:355\u001B[0m, in \u001B[0;36mStudy.train\u001B[1;34m(self, epoch, optimizer, criterion, scheduler, verbose, save_dir, class_weights)\u001B[0m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epoch):\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;66;03m# 使用适当的训练方法\u001B[39;00m\n\u001B[0;32m    354\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m has_classify:\n\u001B[1;32m--> 355\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    356\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    357\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_compatible_train(optimizer, criterion, scheduler)\n",
      "File \u001B[1;32mD:\\知识工程专题实践\\xuezhang\\xuezhang\\src\\tools\\trial.py:192\u001B[0m, in \u001B[0;36mStudy._train\u001B[1;34m(self, optimizer, criterion, scheduler)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# 处理掩码\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    191\u001B[0m     \u001B[38;5;66;03m# 多分类情况\u001B[39;00m\n\u001B[1;32m--> 192\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mout\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m out[mask]\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    193\u001B[0m         \u001B[38;5;66;03m# 确保node_labels是长整型用于CrossEntropyLoss\u001B[39;00m\n\u001B[0;32m    194\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_integral(node_labels):\n\u001B[0;32m    195\u001B[0m             node_labels \u001B[38;5;241m=\u001B[39m node_labels\u001B[38;5;241m.\u001B[39mlong()\n",
      "\u001B[1;31mIndexError\u001B[0m: The shape of the mask [110803] at index 0 does not match the shape of the indexed tensor [110836, 33] at index 0"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 测试"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:17:37.571725Z",
     "start_time": "2025-04-10T10:17:37.571725Z"
    }
   },
   "source": [
    "# test on the model of the last epoch\n",
    "# 带详细指标的测试\n",
    "accuracy, predictions, metrics = study.test(data, return_metrics=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 寻找最佳模型和最佳的topK\n",
    "这里的`topK`是指病人和药品之间概率最`topK`大的边"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# study.find_best(CKPT_DIR, test_graph, NUM_EPOCH * 2, range(1, NUM_EPOCH + 1), range(1, 20))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T10:17:37.574724Z",
     "start_time": "2025-04-10T10:17:37.574724Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
